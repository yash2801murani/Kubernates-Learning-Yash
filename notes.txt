replication controller 

Replicaset - Extendent version of replication controller 


Both are working same but Replicaset is has some more features. 



---------------------------------------------------------------------------------------------------------------------------------------

Que....

Supose we have 3 pod working with nginx without labels and now we want Replicaset to manage this pods and ensure keep on 3
can working continuously. 

so can we need to add template pod in Replicaset yaml?? please note we have already running pods with image and all. 

Ans : Yes.... Definately required bcz once pod get failed Replicaset requires pod template to initiate the new pod. 


---------------------------------------------------------------------------------------------------------------------------

kubectl scale --replicas=6  Replicaset/replicasetname


---------------------------------------------------------------------------------------------------------------------------

Deployments

kubectl set image deployment/<deployment-name> <container-name>=<new-image>

üîπ Update Deployment Image
EG : kubectl set image deployment/nginx-deploy nginx=nginx:1.27

üîπ View Rollout Status
kubectl rollout status deployment/nginx-deploy

üîπ View Rollout History
kubectl rollout history deployment/nginx-deploy


üîπ Rollback to Previous Version
kubectl rollout undo deployment/nginx-deploy

---------------------------------------------------------------------------------------------------------------------------


Services 

‚úÖ What is a Service?

A Service in Kubernetes is a permanent IP and name
that helps other apps connect to your Pods.

Pods keep changing‚Ä¶
Service stays same always.

üü© Why do we need Services?
1Ô∏è‚É£ Pods are not permanent

Pods die, restart, new pods come ‚Üí their IP changes.
Service gives one fixed IP.

2Ô∏è‚É£ To access the application

If you want to reach your app running in pods,
you need a service to expose it.

3Ô∏è‚É£ Load balancing

If you have multiple pods,
Service sends traffic to all of them (round-robin load balancing).

4Ô∏è‚É£ Communication between apps

Backend ‚Üí Frontend
Frontend ‚Üí Database
Services connect them easily.

5Ô∏è‚É£ Stable DNS name

Example:
nginx-service.default.svc.cluster.local

Always same, even if pods change.

üü¶ Types of Services (very simple)
1. ClusterIP (default)

Works inside cluster only

No external access

Used for internal communication
Example: backend communicating with database.

2. NodePort

Opens a port on every node

You can access service using NodeIP:NodePort

Used for testing / exposing to outside world

3. LoadBalancer

Cloud providers (AWS, GCP, Azure)

Creates a real load balancer

Best for production external apps

4. ExternalName

Maps a service name to an external URL
Example: MySQL on another server

üü© In one line:

Pods keep changing. Service gives a stable way to connect to them.


In Depth node port


In all the worker node same port should be open 30000-32767

port : port of svc
nodePort : Port of the actual Machine
Targetport : port of the container where service is running 


if i create node port service for nginx where pods are in 3 multiple worker node 

means 3 worker node ip should open same nodeport port and then using any ip of worker node you can access your resource using the same nodeport number. 




Cluster IP

Internal communication between pods and vm in cluster
not for exposing out side the cluster

eg communicating between frontend and backend. 

allocate single ip called ClusterIP


Load Balancer. 

Focus on the frontend pods 

LB Service -> Pod1(Node1)
           -> Pod2(Node2)
           -> Pod3(Node3)

---------------------------------------------------------------------------------------------------------------------------



Namespace :

Logical devide of k8s cluster

Kubernetes Namespace ‚Äî Simple Notes

A namespace is a way to divide a Kubernetes cluster into smaller logical groups.

It works like separate folders inside the same cluster.

Helps in organizing resources and avoiding name conflicts.

Used to separate environments like dev, test, prod.

You can set resource limits per namespace.

You can control who can access what using RBAC for each namespace.

Some namespaces are created by default:
default, kube-system, kube-public, kube-node-lease.

Resources inside one namespace cannot see resources in another unless exposed.

If you don‚Äôt mention a namespace, Kubernetes uses the default one.


---------------------------------------------------------------------------------------------------------------------------

explanation of Imperative vs Declarative ‚Äî based on what you actually do in real clusters üëá

üü¶ Imperative in Kubernetes (Practical Understanding)

You give Kubernetes direct commands to perform actions immediately.

Practical examples:

You want a pod ‚Üí you run a command ‚Üí pod is created.

You want to delete a service ‚Üí you run a command ‚Üí service is removed.

You want replicas = 5 ‚Üí you run a command ‚Üí replica count changes.

ü§î What happens practically?

No history

No YAML

You must remember all commands manually

Not suitable for big apps

Real commands (for understanding, not explanation):

Create pod

Scale deployment

Delete pod

These actions happen instantly when you run the command.

üü© Declarative in Kubernetes (Practical Understanding)

You create a YAML file that describes your final desired state.

Practical examples:

You create a file that says:
‚ÄúThis deployment should always have 3 pods.‚Äù
‚ÄúThis service should expose port 80.‚Äù

Kubernetes continuously maintains that state.

If a pod is deleted, Kubernetes recreates it automatically.

If someone changes something manually, Kubernetes puts it back to the desired state.

ü§î What happens practically?

YAML acts like documentation

Version controlled (Git)

Easy for teams

Kubernetes self-heals according to the YAML

Real usage:

You apply YAML files to deploy apps

You use Git to store these files

You use tools like ArgoCD / Flux for GitOps


---------------------------------------------------------------------------------------------------------------------------

Kubectl apply command

localfile : yaml
liveObjectConfiguration : K8s managerd
JSON file : k8s Managed

Any change made on local file

kubectl apply -f file name make change in the liveObjectConfiguration

then it finally updated into the json file which is managed by k8s it self. 

stored into the liveObjectConfiguration with in annotation with lastappliedconfiguration.json

---------------------------------------------------------------------------------------------------------------------------

 When manual schuduling happens if you want that specific pod should go to specific node
 in deployment file under metadata use nodeName : nodenameofworker to schuduling the pod of required node only. 
 
---------------------------------------------------------------------------------------------------------------------------

